{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_point_id</th>\n",
       "      <th>meter_id</th>\n",
       "      <th>interval_end_datetime</th>\n",
       "      <th>meter_channel</th>\n",
       "      <th>kwh</th>\n",
       "      <th>account_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2300822246</td>\n",
       "      <td>L108605388</td>\n",
       "      <td>10/1/2022 12:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.594</td>\n",
       "      <td>30010320353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2300822246</td>\n",
       "      <td>L108605388</td>\n",
       "      <td>10/1/2022 12:15:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.101</td>\n",
       "      <td>30010320353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2300822246</td>\n",
       "      <td>L108605388</td>\n",
       "      <td>10/1/2022 12:30:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.104</td>\n",
       "      <td>30010320353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2300822246</td>\n",
       "      <td>L108605388</td>\n",
       "      <td>10/1/2022 12:45:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.106</td>\n",
       "      <td>30010320353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2300822246</td>\n",
       "      <td>L108605388</td>\n",
       "      <td>10/1/2022 1:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.099</td>\n",
       "      <td>30010320353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500275</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 7:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.242</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500276</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 8:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.202</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500277</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 9:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.186</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500278</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 10:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.150</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500279</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 11:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.120</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        service_point_id    meter_id  interval_end_datetime  meter_channel  \\\n",
       "0             2300822246  L108605388  10/1/2022 12:00:00 AM             10   \n",
       "1             2300822246  L108605388  10/1/2022 12:15:00 AM             10   \n",
       "2             2300822246  L108605388  10/1/2022 12:30:00 AM             10   \n",
       "3             2300822246  L108605388  10/1/2022 12:45:00 AM             10   \n",
       "4             2300822246  L108605388   10/1/2022 1:00:00 AM             10   \n",
       "...                  ...         ...                    ...            ...   \n",
       "500275        2300588897  L108607371   9/30/2021 7:00:00 PM             10   \n",
       "500276        2300588897  L108607371   9/30/2021 8:00:00 PM             10   \n",
       "500277        2300588897  L108607371   9/30/2021 9:00:00 PM             10   \n",
       "500278        2300588897  L108607371  9/30/2021 10:00:00 PM             10   \n",
       "500279        2300588897  L108607371  9/30/2021 11:00:00 PM             10   \n",
       "\n",
       "          kwh account_number  \n",
       "0       0.594    30010320353  \n",
       "1       0.101    30010320353  \n",
       "2       0.104    30010320353  \n",
       "3       0.106    30010320353  \n",
       "4       0.099    30010320353  \n",
       "...       ...            ...  \n",
       "500275  1.242    35012790198  \n",
       "500276  1.202    35012790198  \n",
       "500277  1.186    35012790198  \n",
       "500278  1.150    35012790198  \n",
       "500279  1.120    35012790198  \n",
       "\n",
       "[500280 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.dataframes import *\n",
    "\n",
    "meter_usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_point_id</th>\n",
       "      <th>meter_id</th>\n",
       "      <th>interval_end_datetime</th>\n",
       "      <th>meter_channel</th>\n",
       "      <th>kwh</th>\n",
       "      <th>account_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2300588853</td>\n",
       "      <td>L123057647</td>\n",
       "      <td>10/1/2022 12:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.043</td>\n",
       "      <td>35012787756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2300588853</td>\n",
       "      <td>L123057647</td>\n",
       "      <td>10/1/2022 12:15:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.040</td>\n",
       "      <td>35012787756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2300588853</td>\n",
       "      <td>L123057647</td>\n",
       "      <td>10/1/2022 12:30:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045</td>\n",
       "      <td>35012787756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2300588853</td>\n",
       "      <td>L123057647</td>\n",
       "      <td>10/1/2022 12:45:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.040</td>\n",
       "      <td>35012787756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2300588853</td>\n",
       "      <td>L123057647</td>\n",
       "      <td>10/1/2022 1:00:00 AM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.045</td>\n",
       "      <td>35012787756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500275</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 7:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.242</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500276</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 8:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.202</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500277</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 9:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.186</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500278</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 10:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.150</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500279</th>\n",
       "      <td>2300588897</td>\n",
       "      <td>L108607371</td>\n",
       "      <td>9/30/2021 11:00:00 PM</td>\n",
       "      <td>10</td>\n",
       "      <td>1.120</td>\n",
       "      <td>35012790198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500280 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        service_point_id    meter_id  interval_end_datetime  meter_channel  \\\n",
       "0             2300588853  L123057647  10/1/2022 12:00:00 AM             10   \n",
       "1             2300588853  L123057647  10/1/2022 12:15:00 AM             10   \n",
       "2             2300588853  L123057647  10/1/2022 12:30:00 AM             10   \n",
       "3             2300588853  L123057647  10/1/2022 12:45:00 AM             10   \n",
       "4             2300588853  L123057647   10/1/2022 1:00:00 AM             10   \n",
       "...                  ...         ...                    ...            ...   \n",
       "500275        2300588897  L108607371   9/30/2021 7:00:00 PM             10   \n",
       "500276        2300588897  L108607371   9/30/2021 8:00:00 PM             10   \n",
       "500277        2300588897  L108607371   9/30/2021 9:00:00 PM             10   \n",
       "500278        2300588897  L108607371  9/30/2021 10:00:00 PM             10   \n",
       "500279        2300588897  L108607371  9/30/2021 11:00:00 PM             10   \n",
       "\n",
       "          kwh  account_number  \n",
       "0       0.043     35012787756  \n",
       "1       0.040     35012787756  \n",
       "2       0.045     35012787756  \n",
       "3       0.040     35012787756  \n",
       "4       0.045     35012787756  \n",
       "...       ...             ...  \n",
       "500275  1.242     35012790198  \n",
       "500276  1.202     35012790198  \n",
       "500277  1.186     35012790198  \n",
       "500278  1.150     35012790198  \n",
       "500279  1.120     35012790198  \n",
       "\n",
       "[500280 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.runtime import connect_to_db\n",
    "\n",
    "electric_brew = connect_to_db()\n",
    "\n",
    "electric_brew.execute(\"SELECT * FROM meter_usage\").fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "electric_brew.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Analysis Ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ideas\n",
    "\n",
    "1. ~~**Model Validation the Right Way: Holdout Sets**~~\n",
    "   - ~~Develop a model validation strategy using holdout sets extracted from the `fct_electric_brew` dataset. These sets should focus on different billing intervals, various meters, and distinct operational periods (like peak and off-peak hours). The objective is to assess the model's predictive accuracy in real-world scenarios, especially for forecasting energy consumption and associated costs during different periods.~~\n",
    "\n",
    "   - ~~Plot residuals for each of the models' holdout sets~~  \n",
    "<br>\n",
    "\n",
    "1. ~~**Model Validation via Cross-Validation**~~\n",
    "   - ~~Implement a robust cross-validation framework on `dim_datetimes` and `fct_electric_brew` datasets. This framework should assess the consistency and reliability of predictive models across various temporal segments, such as different months, weeks, or specific operational hours, to enhance the accuracy of peak hour energy consumption predictions.~~   \n",
    "<br>\n",
    "\n",
    "1. **Learning Curves**\n",
    "   - Analyze learning curves by incrementally increasing the volume of training data from the `fct_electric_brew` dataset, which includes varied energy consumption patterns. Evaluate how different machine learning models improve or stabilize in performance as more data is fed into them. This analysis aims to determine the point of diminishing returns in terms of data volume and its effect on model performance.  \n",
    "<br>\n",
    "\n",
    "1. **Bayesian Classification**\n",
    "   - Utilize Bayesian classification techniques on the `fct_electric_brew` dataset to make probabilistic predictions about energy usage patterns. This approach will be particularly beneficial in assessing the likelihood of different consumption patterns and their impact on cost, which is crucial in ROI analyses and risk assessment.  \n",
    "<br>\n",
    "\n",
    "1.  **Polynomial Basis Functions**\n",
    "    - Investigate and model non-linear relationships within the `dim_datetimes` and `fct_electric_brew` datasets. This exploration should focus on uncovering complex patterns in energy consumption during peak hours, using polynomial basis functions to represent these non-linear relationships in the predictive models.  \n",
    "<br>\n",
    "\n",
    "1.  **Regularization**\n",
    "    - Implement regularization techniques in predictive models that combine features from `dim_datetimes`, `dim_meters`, `dim_bills`, and `fct_electric_brew`. The goal is to control model complexity, particularly in models predicting various aspects of energy consumption, and prevent overfitting by penalizing large or irrelevant model coefficients.  \n",
    "<br>\n",
    "\n",
    "1.  **Feature Ranking, PCR, and Lasso Regression (hw07)**\n",
    "    - Apply Lasso regression across all dimensions, including `dim_datetimes`, `dim_meters`, `dim_bills`, and `fct_electric_brew`, to conduct feature selection. This method will identify the most impactful predictors across different datasets, revealing the variables that significantly influence peak hour energy consumption and cost patterns.  \n",
    "<br>\n",
    "\n",
    "1.  **Principal Component Analysis**\n",
    "    - Perform Principal Component Analysis (PCA) on the `dim_bills` dataset to reduce its dimensionality. This technique will help in identifying the most significant billing factors and underlying patterns, simplifying complex billing data into principal components that retain the most important information for predictive modeling.  \n",
    "<br>\n",
    "\n",
    "1.  **Anomaly Detection**\n",
    "    - Deploy anomaly detection algorithms to identify unusual patterns or outliers in cost and consumption data within the `fct_electric_brew` dataset. This analysis aims to pinpoint inefficiencies, potential errors, or opportunities for cost savings, especially in peak hour energy usage.  \n",
    "<br>\n",
    "\n",
    "1.  **Time-Based Forecasting**\n",
    "    - Use advanced time series forecasting methods on `dim_datetimes` and `dim_bills` to predict future energy costs and consumption patterns. This forecasting will help in strategic planning and decision-making, particularly in identifying potential benefits of shifting energy usage to off-peak times.  \n",
    "<br>\n",
    "\n",
    "1.  **K-Means Clustering**\n",
    "    - Apply K-Means Clustering to the `fct_electric_brew` dataset to segment and analyze different patterns of energy consumption and associated costs. This clustering will assist in identifying distinct consumption groups or patterns within the brewery, facilitating targeted strategies for cost reduction and energy management.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataframes import fct_electric_brew, dim_datetimes, dim_meters, dim_bills\n",
    "from utils.runtime    import setup_plot_params\n",
    "\n",
    "from sklearn.compose       import ColumnTransformer\n",
    "from sklearn.ensemble      import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model  import LinearRegression\n",
    "from sklearn.pipeline      import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "def setup_analysis(temporal_only : bool = False) -> dict:\n",
    "    '''\n",
    "    This utility function consolidates the data preparation and model setup steps for various analyses of the `fct_electric_brew` dataset,\n",
    "    in the spirit of DRY.\n",
    "     \n",
    "    It merges related data tables, extracts features, sets up preprocessing pipelines, and initializes a set of models for further analysis. \n",
    "    The function is designed to standardize these steps across different analyses, ensuring consistency and efficiency.\n",
    "\n",
    "    Methodology:\n",
    "        1. Data Merging: Combine `fct_electric_brew` with `dim_datetimes`, `dim_meters`, and `dim_bills` for a comprehensive dataset.\n",
    "        2. Feature Engineering: Select relevant features for analysis, focusing on key aspects like time, meter readings, and supplier.\n",
    "        3. Preprocessing Setup: Standardize numerical features and encode categorical features for machine learning algorithms.\n",
    "        4. Model Initialization: Set up pipelines for various regression models, including Linear Regression, Random Forest, and Gradient Boosting.\n",
    "        5. Output Packaging: Return a dictionary containing prepared data, features, target variable, and model pipelines.\n",
    "\n",
    "    Note: For Step 2, the `temporal_only` argument allows for the selection of only time-related features if set to True.\n",
    "\n",
    "    Mathematical Concepts:\n",
    "        • Standardization (Z-Score Normalization):\n",
    "            - Formula: z = (x - μ) / σ\n",
    "            - Purpose: Scales features to have a mean (μ) of zero and a variance (σ) of one.\n",
    "\n",
    "        • One-Hot Encoding:\n",
    "            - Purpose: Transforms categorical variables into a binary matrix, enabling easier processing by machine learning models.\n",
    "\n",
    "        • Regression Modeling:\n",
    "            - Concept: Techniques used to predict a continuous target variable based on one or more input features.\n",
    "\n",
    "        • Pipeline Creation:\n",
    "            - Purpose: Streamlines preprocessing and modeling steps into a single, unified process for more efficient analysis.\n",
    "\n",
    "    Produces:\n",
    "        - A comprehensive dataset ready for analysis.\n",
    "        - A set of preprocessed features and a target variable.\n",
    "        - A dictionary of machine learning model pipelines, primed for training and evaluation.\n",
    "    '''\n",
    "\n",
    "    setup_plot_params()\n",
    "\n",
    "    # Joining fact and dimension tables\n",
    "    data = fct_electric_brew.merge(dim_datetimes, how = 'left', left_on = 'dim_datetimes_id', right_on = 'id', suffixes = ('', '_dd')) \\\n",
    "                            .merge(dim_meters,    how = 'left', left_on = 'dim_meters_id',    right_on = 'id', suffixes = ('', '_dm')) \\\n",
    "                            .merge(dim_bills,     how = 'left', left_on = 'dim_bills_id',     right_on = 'id', suffixes = ('', '_db'))\n",
    "\n",
    "    # Feature selection and engineering\n",
    "    temporal = [] if temporal_only else ['meter_id', 'supplier']\n",
    "    features = data[['hour', 'week', 'month', 'quarter', 'year', 'period', 'kwh'] + temporal]\n",
    "    target   = data['total_cost']\n",
    "\n",
    "    # Step 2: Model Selection & Pipelines\n",
    "    # Preprocessing for numerical and categorical features\n",
    "    categorical = ['period'] + temporal\n",
    "    numerical   = [col for col in features.columns if col not in categorical]\n",
    "\n",
    "    preprocessor = ColumnTransformer(transformers = [('num', StandardScaler(), numerical),\n",
    "                                                     ('cat', OneHotEncoder(),  categorical)])\n",
    "\n",
    "    # Define models within a pipeline to ensure consistent preprocessing\n",
    "    models = {'Linear Regression' : Pipeline([('preprocessor', preprocessor), \n",
    "                                              ('regressor',    LinearRegression())]),\n",
    "\n",
    "              'Random Forest'     : Pipeline([('preprocessor', preprocessor), \n",
    "                                              ('regressor',    RandomForestRegressor())]),\n",
    "\n",
    "              'Gradient Boosting' : Pipeline([('preprocessor', preprocessor), \n",
    "                                              ('regressor',    GradientBoostingRegressor())])}\n",
    "\n",
    "    return {'data'     : data,\n",
    "            'features' : features,\n",
    "            'target'   : target,\n",
    "            'models'   : models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts after DRY Function\n",
    "\n",
    "- Left joining on all DataFrames is resulting in additional processing time for both of the established functions\n",
    "- How should nulls be handled in the dataset?\n",
    "- Unclear why TCA is taking longer, but might be due to `kwh` being included as a Standardized feature in this version\n",
    "- Should time components be sorted into any particular order before TCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Model Validation Using Holdout Sets\n",
    "\n",
    "This script develops a model validation strategy using holdout sets from the `fct_electric_brew` dataset. The focus is\n",
    "on forecasting energy consumption and associated costs across different periods, and the initial interest is in determining\n",
    "which regressor might be best suited for a dataset of this size with this many key features, using standard parameters like\n",
    "a holdout size of 30%.\n",
    "\n",
    "Methodology:\n",
    "    1. Analysis Setup: Call `setup_analysis` to prepare underlying data and initialize model pipelines\n",
    "    3. Dataset Splitting: Stratify data into training and holdout sets to validate each model against unbiased data.\n",
    "    4. Model Training: Fit models on training data, enabling them to uncover underlying data patterns.\n",
    "    5. Model Evaluation & Visualization: Assess models on holdout set, then visualize prediction accuracy and residuals.\n",
    "\n",
    "Mathematical Concepts:\n",
    "    • Linear Regression:\n",
    "        - Formula: y = β₀ + β₁x₁ + ... + βₙxₙ\n",
    "        - Purpose: Predicts a dependent variable value (y) based on independent variables (x).\n",
    "\n",
    "    • Random Forest:\n",
    "        - Concept: An ensemble learning method that constructs multiple decision trees at training and outputs the mode of \n",
    "                   classes for classification or mean prediction for regression.\n",
    "\n",
    "    • Gradient Boosting:\n",
    "        - Concept: Boosting method combining weak predictive models (typically decision trees) to create a strong predictor.\n",
    "\n",
    "    • R² (Coefficient of Determination):\n",
    "        - Formula: R² = 1 - Σ(yᵢ - f(xᵢ))² / Σ(yᵢ - ȳ)²\n",
    "        - Purpose: Measures the proportion of the variance for the dependent variable explained by the independent variables.\n",
    "\n",
    "Produces:\n",
    "    - Trained and validated models with performance insights.\n",
    "    - Visualizations highlighting model predictions and performance.\n",
    "'''\n",
    "\n",
    "import numpy   as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics         import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.runtime           import find_project_root\n",
    "\n",
    "# Step 1: Analysis Setup\n",
    "setup    = setup_analysis()\n",
    "features = setup['features']\n",
    "target   = setup['target']\n",
    "models   = setup['models']\n",
    "\n",
    "# Step 2: Dataset Splitting\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(features, \n",
    "                                                          target, \n",
    "                                                          test_size    = 0.3, \n",
    "                                                          random_state = 42)\n",
    "\n",
    "# Step 3: Training and Validation\n",
    "for name, pipeline in models.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Model Evaluation & Visualization\n",
    "plt.figure(figsize = (20, 10))\n",
    "\n",
    "for i, (name, pipeline) in enumerate(models.items()):\n",
    "\n",
    "    y_pred    = pipeline.predict(X_holdout)\n",
    "    residuals = abs(y_holdout - y_pred)\n",
    "    r2        = r2_score(y_holdout, y_pred)\n",
    "\n",
    "    # Print model performance metrics\n",
    "    print(f\"{name}\",\n",
    "          f\"    MSE : {mean_squared_error(y_holdout,  y_pred):.4f}\",\n",
    "          f\"    MAE : {mean_absolute_error(y_holdout, y_pred):.4f}\",    \n",
    "          f\"    R²  : {r2:.4f}\",\n",
    "          sep='\\n')\n",
    "\n",
    "    # Model visualization\n",
    "    plt.subplot(1, len(models), i + 1)\n",
    "    plt.plot(y_holdout, y_holdout, color = '1', linewidth = 2, linestyle = ':') # Perfect prediction line\n",
    "    sns.scatterplot(x = y_holdout, \n",
    "                    y = y_pred, \n",
    "                    c = np.power(residuals, 0.3), # More aggressive colormapping (i.e. creates more distance from 0)\n",
    "                    cmap      = 'cividis_r',                  \n",
    "                    alpha     = 0.6, \n",
    "                    edgecolor = None)\n",
    "    \n",
    "    plt.xlabel('Actual Total Cost'    if i == 1 else '')\n",
    "    plt.ylabel('Predicted Total Cost' if i == 0 else '')\n",
    "    plt.title(f'{name} ($R²$: {r2:.4f})')\n",
    "\n",
    "plt.suptitle('Model Validation Using Holdout Sets', weight = 'bold', fontsize = 15)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{find_project_root('./fig/analysis/01 - Model Validation Using Holdout Sets.png')}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/Macington/Documents/Projects/Electric Brew/src/jp/analysis.ipynb Cell 11\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m tscv  \u001b[39m=\u001b[39m TimeSeriesSplit(n_splits \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Step 3: RandomForest Training & Evaluation\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m cv_scores \u001b[39m=\u001b[39m cross_val_score(model, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m                             features, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m                             target, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m                             cv      \u001b[39m=\u001b[39;49m tscv, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m                             scoring \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mneg_mean_squared_error\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m cv_norm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(cv_scores) \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mmax(np\u001b[39m.\u001b[39mabs(cv_scores))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/Macington/Documents/Projects/Electric%20Brew/src/jp/analysis.ipynb#X11sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Step 4: Annotated Visualization\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    574\u001b[0m )\n\u001b[1;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m    312\u001b[0m         X,\n\u001b[1;32m    313\u001b[0m         y,\n\u001b[1;32m    314\u001b[0m         scorers,\n\u001b[1;32m    315\u001b[0m         train,\n\u001b[1;32m    316\u001b[0m         test,\n\u001b[1;32m    317\u001b[0m         verbose,\n\u001b[1;32m    318\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    319\u001b[0m         fit_params,\n\u001b[1;32m    320\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    321\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    322\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    323\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    324\u001b[0m     )\n\u001b[1;32m    325\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m indices\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:729\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    727\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    728\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 729\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    731\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/pipeline.py:427\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    425\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    426\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 427\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    429\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    445\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    447\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    448\u001b[0m ]\n\u001b[1;32m    450\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 456\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    457\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    458\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    459\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    460\u001b[0m )(\n\u001b[1;32m    461\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    462\u001b[0m         t,\n\u001b[1;32m    463\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    464\u001b[0m         X,\n\u001b[1;32m    465\u001b[0m         y,\n\u001b[1;32m    466\u001b[0m         sample_weight,\n\u001b[1;32m    467\u001b[0m         i,\n\u001b[1;32m    468\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    469\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    470\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    471\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    474\u001b[0m )\n\u001b[1;32m    476\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    477\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/joblib/parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39m(output)\n\u001b[1;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/joblib/parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 188\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    189\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/tree/_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1291\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   1292\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \n\u001b[1;32m   1294\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1318\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1320\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_fit(\n\u001b[1;32m   1321\u001b[0m         X,\n\u001b[1;32m   1322\u001b[0m         y,\n\u001b[1;32m   1323\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1324\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1325\u001b[0m     )\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/electric-brew/lib/python3.11/site-packages/sklearn/tree/_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    433\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    434\u001b[0m         splitter,\n\u001b[1;32m    435\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    441\u001b[0m     )\n\u001b[0;32m--> 443\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight, missing_values_in_feature_mask)\n\u001b[1;32m    445\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    446\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "Temporal Consistency Analysis via Cross-Validation\n",
    "\n",
    "This script conducts a detailed temporal consistency analysis using the RandomForestRegressor on the merged `fct_electric_brew` \n",
    "dataset with `dim_datetimes` features included. \n",
    "\n",
    "It aims to evaluate the model's performance over different time segments, focusing on its ability to forecast energy consumption \n",
    "and costs reliably across these periods.\n",
    "\n",
    "Methodology:\n",
    "    1. Analysis Setup: Call `setup_analysis` with temporal features only to prepare underlying data and initialize the pipeline.\n",
    "    2. Cross-Validation Setup: Implement TimeSeriesSplit to assess model performance over successive time splits.\n",
    "    3. RandomForest Evaluation: Train the RandomForestRegressor on temporal features only and evaluate using cross-validation.\n",
    "    4. Annotated Visualization: Plot cross-validation scores with annotations for data volume in each split.\n",
    "\n",
    "Mathematical Concepts:\n",
    "    • Time Series Analysis:\n",
    "        - Purpose: Analyze time-ordered data points to identify trends, patterns, and seasonal variations.\n",
    "    \n",
    "    • Cross-Validation (TimeSeriesSplit):\n",
    "        - Purpose: Evaluate model's prediction reliability over time, ensuring that training occurs only on past data.\n",
    "    \n",
    "    • RandomForestRegressor:\n",
    "        - Concept: An ensemble method using multiple decision trees to improve prediction accuracy and control over-fitting.\n",
    "    \n",
    "    • Mean Squared Error (MSE):\n",
    "        - Formula: MSE = 1/n Σ(yᵢ - ŷᵢ)²\n",
    "        - Purpose: Quantify the average magnitude of the errors between predicted and actual values.\n",
    "\n",
    "Produces:\n",
    "    - Visualization of model performance over time, highlighting any variances and data volume.\n",
    "'''\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from utils.runtime           import find_project_root\n",
    "\n",
    "# Step 1: Analysis Setup\n",
    "setup    = setup_analysis(True) # Temporal features only\n",
    "features = setup['features']\n",
    "target   = setup['target']\n",
    "model    = setup['models']['Random Forest']\n",
    "\n",
    "# Step 2: Cross-Validation Setup\n",
    "tscv  = TimeSeriesSplit(n_splits = 10)\n",
    "\n",
    "# Step 3: RandomForest Training & Evaluation\n",
    "cv_scores = cross_val_score(model, \n",
    "                            features, \n",
    "                            target, \n",
    "                            cv      = tscv, \n",
    "                            scoring = 'neg_mean_squared_error')\n",
    "\n",
    "cv_norm = np.abs(cv_scores) / np.max(np.abs(cv_scores))\n",
    "\n",
    "# Step 4: Annotated Visualization\n",
    "bars = plt.bar(range(tscv.n_splits), cv_scores, color = plt.cm.cividis_r(cv_norm))\n",
    "\n",
    "# Formatted Size Annotations\n",
    "split_sizes = [len(holdout_index) for holdout_index, _ in tscv.split(features)]\n",
    "for bar, size in zip(bars, split_sizes):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, \n",
    "             0, \n",
    "             f'Size: {size:,}',\n",
    "             va   = 'bottom', \n",
    "             ha   = 'center')\n",
    "    \n",
    "plt.xlabel('Time Split')\n",
    "plt.ylabel('Cross-Validation Score ($-MSE$)')\n",
    "plt.title('Temporal Consistency of the Random Forest Regressor')\n",
    "plt.xticks(range(tscv.n_splits), [f'Split {i + 1}' for i in range(tscv.n_splits)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(find_project_root('./fig/analysis/02 - Temporal Consistency of the Random Forest Regressor.png'))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "electric-brew",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
